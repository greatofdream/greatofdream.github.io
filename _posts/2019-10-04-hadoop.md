---
layout: post
title:
date: 2019-10-04
---
## hadoop:pill:

位于etc/hadoop-env.sh中的**JAVA_HOME**似乎应该需要[配置绝对路径](https://stackoverflow.com/questions/20628093/java-home-is-not-set-in-hadoop)

使用hadoop3.2.1时，openjdk9似乎有问题，使用yarn时会报错声称
```
2019-10-04 16:21:59,566 INFO mapreduce.Job: Job job_1570176818335_0003 failed with state FAILED due to: 
Application application_1570176818335_0003 failed 2 times due to Error launching appattempt_1570176818335_0003_000002. 
Got exception: org.apache.hadoop.security.AccessControlException: Unable to find SASL server implementation for DIGEST-MD5
```
换成openjdk8
```
[2019-10-04 17:17:02.073]Container exited with a non-zero exit code 127. Error file: prelaunch.err.
Last 4096 bytes of prelaunch.err :
Last 4096 bytes of stderr :
/bin/bash: /bin/java: No such file or directory
```

换成oracle jdk8
报错和openjdk8一致
只好强行在/bin/中写入文件连接
```
ls -s /usr/bin/java /bin/java
```
在另一台机器配置了host文件，将对应的域名指向127.0.0.1，发现竟然没有这个错误。

配置分布式后发现启动没有Namenode,resourcemanager，果断将/etc/hosts域名指向127.0.0.1，解决了这个问题，重新启动就正常了


重启会报错
```
 org.apache.hadoop.hdfs.server.common.InconsistentFSStateException: Directory /tmp/hadoop-ubuntu/dfs/name is in an inconsistent state
```
有问答指出[tmp会被清理](https://stackoverflow.com/questions/17376982/org-apache-hadoop-hdfs-server-common-inconsistentfsstateexception-directory-tm)
因此调整core-site.xml中对于**tmp.dir**设置

发现host配置错误会卡在resourcesmanager上，本机名字对应的ip一定要是**127.0.0.1**放在第一位
否则报错
```
 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032
 ```
 
直接在master节点执行命令发现报错，
```
-bash: bin/dfs: No such file or directory
```
slave节点未完整配置$HADOOP_HOME和$path，一股脑全都加了进去，bin/hdfs就可以找到了。

配置分布式后始终不能连接,logs中datanode显示无法连接master，master对应9000端口为127.0.0.1:9000显然不能访问，尝试多次后将core-site.xml中的域名直接改为对应ip，将slave对应的host文件改成对应iP即可，同时telnet也可以成功连接上master。

但是新的问题是腾讯云提供了两个ip，使用master公网ip根本无法连通，datanode.log中显示一直在retry，telnet也无法成功，似乎是腾讯云有某种过滤机制。

使用私有地址的ip,telnet可以成功，但是新的报错出现
```
 Datanode denied communication with namenode because hostname cannot be resolved
 (ip=172.21.101.4, hostname=172.21.101.4)
 ```
 
 发现了两种解决方案，其中[详细代码解释](https://blog.csdn.net/lulynn/article/details/46725683)很棒,[stackoverflow](https://stackoverflow.com/questions/27195466/hdfs-datanode-denied-communication-with-namenode-because-hostname-cannot-be-reso)也有人提出相关问题
 
 最后采用在master和slave上的**core-site**中加入
 ```
 <property>
           <name>dfs.namenode.datanode.registration.ip-hostname-check</name>                   
           <value>false</value>
 </property>
 ```
slave和master成功通信
